from fastapi import FastAPI
from pydantic import BaseModel
from typing import List, Dict, Any
import datetime
import re

app = FastAPI()

# ===== æ•°æ®ç»“æ„ =====
class DataPoint(BaseModel):
    time: str
    text: str

class InputData(BaseModel):
    data: List[DataPoint]

# ===== å·¥å…·å‡½æ•° =====
def is_ai_output(text: str) -> bool:
    """
    åˆ¤æ–­è¾“å…¥æ˜¯å¦æ›´åƒæ¨¡å‹è¾“å‡ºè€Œä¸æ˜¯åŸå§‹æ–‡æœ¬
    """
    markers = ["ç»“è®º", "æ€»ç»“", "åˆ†æ", "å»ºè®®", "æŠ¥å‘Š", "1.", "2.", "3.", "â€¢", "- "]
    return any(m in text for m in markers) and len(text.split()) > 30

def extract_keywords(text: str, topk: int = 5) -> List[str]:
    # ç®€åŒ–å®ç°ï¼šå–å‰ topk ä¸ªç‹¬ç‰¹è¯
    words = re.findall(r'\w+', text)
    freq = {}
    for w in words:
        freq[w] = freq.get(w, 0) + 1
    return sorted(freq, key=freq.get, reverse=True)[:topk]

def analyze_sentiment(text: str) -> str:
    if any(w in text for w in ["good", "great", "happy", "positive", "excellent", "å¥½", "æ»¡æ„"]):
        return "positive"
    elif any(w in text for w in ["bad", "sad", "angry", "negative", "å·®", "ä¸æ»¡"]):
        return "negative"
    return "neutral"

def cluster_texts(texts: List[str]) -> List[Dict[str, Any]]:
    keywords = extract_keywords(" ".join(texts))
    clusters = []
    for kw in keywords:
        examples = [t for t in texts if kw.lower() in t.lower()]
        clusters.append({"topic": kw, "examples": examples[:3]})
    return clusters

def trend_analysis(times: List[str], texts: List[str]) -> Dict[str, Any]:
    # æŒ‰æ—¥æœŸç»Ÿè®¡æ–‡æœ¬æ•°é‡
    daily_count = {}
    for t in times:
        date = t.split("T")[0] if "T" in t else t
        daily_count[date] = daily_count.get(date, 0) + 1
    return {"dates": list(daily_count.keys()), "series": list(daily_count.values())}

def llm_generate_report(texts: List[str], keywords: List[str], clusters: List[Dict[str, Any]]) -> str:
    return f"ğŸ“Š è‡ªåŠ¨æŠ¥å‘Š\nå…³é”®è¯: {', '.join(keywords)}\nèšç±»ä¸»é¢˜æ•°: {len(clusters)}\næ ·æœ¬æ–‡æœ¬æ•°: {len(texts)}"

# ===== ä¸»åˆ†æ API =====
@app.post("/analyze")
def analyze(input_data: InputData):
    texts = [d.text for d in input_data.data]
    times = [d.time for d in input_data.data]

    joined_text = " ".join(texts)

    if is_ai_output(joined_text):
        # âœ… æ¨¡å‹è¾“å‡ºæ¨¡å¼
        mode = "æ¨¡å‹è¾“å‡ºæ¨¡å¼"
        report = joined_text
        keywords = extract_keywords(report)
        clusters = [{"topic": k, "examples": []} for k in keywords[:5]]
        trend_data = {"dates": [], "series": []}  # æ²¡æœ‰æ—¶é—´åºåˆ—
        sentiments = []
    else:
        # âœ… åŸå§‹æ–‡æœ¬æ¨¡å¼
        mode = "åŸå§‹æ–‡æœ¬æ¨¡å¼"
        keywords = extract_keywords(joined_text)
        sentiments = [analyze_sentiment(t) for t in texts]
        clusters = cluster_texts(texts)
        trend_data = trend_analysis(times, texts)
        report = llm_generate_report(texts, keywords, clusters)

    return {
        "mode": mode,
        "report": report,
        "keywords": keywords,
        "clusters": clusters,
        "trend": trend_data,
        "sentiments": sentiments
    }
